{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Eye_Glass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8lh0KKnEAPU"
      },
      "source": [
        "# CNN Train\n",
        "\n",
        "1. Import modules\n",
        "2. Setup `ImageDataGenerator` params\n",
        "3. Make Custom CNN\n",
        "4. Fine Tune Pretrained CNN\n",
        "5. Train the model\n",
        "6. Save Model\n",
        "7. Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RTsuX_Olvh7",
        "outputId": "1b3ce353-aca1-4c23-b2b7-c80b95fa406f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov3LJqRWxNUT"
      },
      "source": [
        "# Download the Dataset[[link]](https://www.kaggle.com/ofirshimshon/glass-project)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IuGIA5Fl1Co",
        "outputId": "e5eb7b7a-ee35-4a59-abd6-ea8b45f407f1"
      },
      "source": [
        "# If you want download direct link from Kaggle by Internet Download Manager > put link here directly \n",
        "# Don't forget to rename the file from left side to \"archive.zip\" to able to Extract it (unzip)\n",
        "!wget \"https://storage.googleapis.com/kaggle-data-sets/1433418/2372367/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210727%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210727T112533Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=9fc0ac9b9af917c13e73323eb8a04d84ad53f7f238679e0ba58323409719f8a310024a827d35b6571cf166d29a0aa8274cfe70cfea6cc4ad4363ed844c7de70137181c81fe75675810a36a6bd3c0d49381e423b41bf17db994dbde0d39b17cdbb39e54a5da931f04c5982e9f2201a51a53e7f55497a0a9bb7e4c21d30c0c48c86f164ac3f8f12fe9681c13ca0bc9721827ab8a03fc029e75c5079a88fdf4960282aef17e32af8837560dcf976eed556a02e1319dc0393b63cc8ffb137e6e22efe61cb8dc0131e13b048fc0f55abdec9f89436f77e5873bfc2503d6bb4e9f4ec7b209f5f15052b5e7c55e9973ad7847432982af2cfe91d5b39707c285e5dc2f99\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The name is too long, 767 chars total.\n",
            "Trying to shorten...\n",
            "New name is archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com%2F20210727%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210727T112533Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=hos.\n",
            "--2021-07-27 11:59:47--  https://storage.googleapis.com/kaggle-data-sets/1433418/2372367/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210727%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210727T112533Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=9fc0ac9b9af917c13e73323eb8a04d84ad53f7f238679e0ba58323409719f8a310024a827d35b6571cf166d29a0aa8274cfe70cfea6cc4ad4363ed844c7de70137181c81fe75675810a36a6bd3c0d49381e423b41bf17db994dbde0d39b17cdbb39e54a5da931f04c5982e9f2201a51a53e7f55497a0a9bb7e4c21d30c0c48c86f164ac3f8f12fe9681c13ca0bc9721827ab8a03fc029e75c5079a88fdf4960282aef17e32af8837560dcf976eed556a02e1319dc0393b63cc8ffb137e6e22efe61cb8dc0131e13b048fc0f55abdec9f89436f77e5873bfc2503d6bb4e9f4ec7b209f5f15052b5e7c55e9973ad7847432982af2cfe91d5b39707c285e5dc2f99\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 74.125.203.128, 74.125.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6500734781 (6.1G) [application/zip]\n",
            "Saving to: ‘archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com%2F20210727%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210727T112533Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=hos’\n",
            "\n",
            "archive.zip?X-Goog- 100%[===================>]   6.05G  55.3MB/s    in 2m 25s  \n",
            "\n",
            "2021-07-27 12:02:13 (42.8 MB/s) - ‘archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com%2F20210727%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210727T112533Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=hos’ saved [6500734781/6500734781]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo6MDkypmRfX"
      },
      "source": [
        "# Extract \n",
        "!unzip -q /content/archive.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oibw3tNNEAPZ"
      },
      "source": [
        "## 1. Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53wVW4__gItj",
        "scrolled": true
      },
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Loading data & model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Pretrained\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "# from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "# from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "\n",
        "\n",
        "# Custom\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6WjlVLSEAPc"
      },
      "source": [
        "## 2. Setup `ImageDataGenerator` params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U--epClfgIt0"
      },
      "source": [
        "TRAIN_DIR = '/content/faces/train'\n",
        "TEST_DIR = '/content/faces/validation'\n",
        "\n",
        "\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI1_UUn9gIuw",
        "outputId": "b9d89e3e-33ee-4b40-e485-2267d705ad58"
      },
      "source": [
        "train_datagen =  ImageDataGenerator(\n",
        "#         preprocessing_function=preprocess_input,\n",
        "        rotation_range=90,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rescale=1./255)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "#         preprocessing_function=preprocess_input,\n",
        "        rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    color_mode = \"rgb\",\n",
        "                                                    class_mode='binary',\n",
        "                                                    shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        TEST_DIR,\n",
        "        target_size=(HEIGHT, WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        color_mode = \"rgb\",\n",
        "        class_mode='binary',\n",
        "        shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3696 images belonging to 2 classes.\n",
            "Found 1261 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJlBlqjnEAPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f7e5b9-9830-4838-d153-458651375292"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glasses': 0, 'no_glasses': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M0il1cREAPg"
      },
      "source": [
        "## 3. Make Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_45iofIEAPg"
      },
      "source": [
        "if os.path.isfile('custom_model.h5'):\n",
        "    model = load_model('custom_model.h5')\n",
        "else:\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(HEIGHT, WIDTH, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D()) \n",
        "    model.add(Dropout(0.3))\n",
        "              \n",
        "              \n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D()) \n",
        "    model.add(Dropout(0.3))\n",
        "              \n",
        "              \n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D()) \n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdZxOg-dEAPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69301c79-c2b4-4b82-c81a-ca107501cf9f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2768928   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,862,209\n",
            "Trainable params: 2,862,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e1s1cy0EAPh"
      },
      "source": [
        "## 4. Fine Tune Pretrained CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khyfooEDEAPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feceff97-00e1-4308-f45a-133fec6bd49b"
      },
      "source": [
        "if os.path.isfile('pretrained_model.h5'):\n",
        "    model = load_model('pretrained_model.h5')\n",
        "else:\n",
        "    pretrained_model = VGG19(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n",
        "\n",
        "    for layer in pretrained_model.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = pretrained_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    predictions = Dense(1, activation='sigmoid')(x) \n",
        "\n",
        "    model = Model(inputs=pretrained_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aumCnD3EAPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc022adf-afd1-4eea-cdcb-1ce4d7e5bb6b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 23,235,905\n",
            "Trainable params: 7,931,137\n",
            "Non-trainable params: 15,304,768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FpkOzV9EAPj"
      },
      "source": [
        "## 5. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpqblyisEAPk"
      },
      "source": [
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVn6oQpUEAPk"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"./custom_model.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTkO8jtTgIwL",
        "scrolled": false,
        "outputId": "52b51a40-84a6-4374-9a28-0b68aca1c46a"
      },
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    validation_data=test_generator, \n",
        "                    epochs=NUM_EPOCHS, \n",
        "                    steps_per_epoch=train_generator.n // BATCH_SIZE, \n",
        "                    validation_steps=test_generator.n // BATCH_SIZE,\n",
        "                    shuffle=True, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "115/115 [==============================] - 374s 3s/step - loss: 0.2374 - accuracy: 0.9345 - val_loss: 0.2103 - val_accuracy: 0.9135\n",
            "115/115 [==============================] - 326s 3s/step - loss: 0.0632 - accuracy: 0.9858 - val_loss: 0.0567 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.21026 to 0.05668, saving model to ./custom_model.h5\n",
            "Epoch 3/10\n",
            "115/115 [==============================] - 300s 3s/step - loss: 0.1030 - accuracy: 0.9776 - val_loss: 0.0513 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.05668 to 0.05132, saving model to ./custom_model.h5\n",
            "Epoch 4/10\n",
            "115/115 [==============================] - 296s 3s/step - loss: 0.1064 - accuracy: 0.9754 - val_loss: 0.0651 - val_accuracy: 0.9880\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.05132\n",
            "Epoch 5/10\n",
            "115/115 [==============================] - 291s 3s/step - loss: 0.1068 - accuracy: 0.9839 - val_loss: 0.0380 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.05132 to 0.03798, saving model to ./custom_model.h5\n",
            "Epoch 6/10\n",
            "115/115 [==============================] - 291s 3s/step - loss: 0.0715 - accuracy: 0.9858 - val_loss: 0.0301 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.03798 to 0.03006, saving model to ./custom_model.h5\n",
            "Epoch 7/10\n",
            "115/115 [==============================] - 286s 2s/step - loss: 0.0601 - accuracy: 0.9883 - val_loss: 0.0554 - val_accuracy: 0.9864\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.03006\n",
            "Epoch 8/10\n",
            "115/115 [==============================] - 288s 3s/step - loss: 0.0618 - accuracy: 0.9874 - val_loss: 0.0413 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.03006\n",
            "Epoch 9/10\n",
            "115/115 [==============================] - 291s 3s/step - loss: 0.0585 - accuracy: 0.9896 - val_loss: 0.0399 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.03006\n",
            "Epoch 10/10\n",
            "115/115 [==============================] - 293s 3s/step - loss: 0.0544 - accuracy: 0.9902 - val_loss: 0.0426 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.03006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KVAMUkVEAPl"
      },
      "source": [
        "## 6. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7VTpZV8EAPm"
      },
      "source": [
        "# model.save('custom_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEdbEUhbEAPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d9c496-389d-40e2-88d5-5b4a4a640eac"
      },
      "source": [
        "classes = list(train_generator.class_indices.keys())\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glasses', 'no_glasses']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM1otU2BEAPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e968e48a-3a5b-422b-9a73-ce31df440ef5"
      },
      "source": [
        "joblib.dump(classes, 'classes.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['classes.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIW2_nGEAPo"
      },
      "source": [
        "## 7. Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r7LDaqZEAPp"
      },
      "source": [
        "**Test on `test_generator`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYRDP4BsEAPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99d19eb-0c7c-4dd4-b2b3-062f977e7d0f"
      },
      "source": [
        "model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 70s 2s/step - loss: 0.0489 - accuracy: 0.9905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.048910319805145264, 0.9904837608337402]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsYVbhM7EAPq"
      },
      "source": [
        "**Test on custom data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaS14sqBuP4_"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp-F59mKEAPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c685c3-5788-4864-9be3-31ac091fec1b"
      },
      "source": [
        "model = load_model('custom_model.h5')\n",
        "\n",
        "classes = joblib.load('classes.h5')\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glasses', 'no_glasses']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBBz_FUNEAPs"
      },
      "source": [
        "def test_on(path):\n",
        "    img = image.load_img(path, target_size=(HEIGHT, WIDTH, 3))\n",
        "    img = image.img_to_array(img)\n",
        "#     img = preprocess_input(img)\n",
        "    img = img / 255.\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return 'No glasses' if model.predict(img) > 0.5 else 'glasses'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPG6eh5EAPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9b7c9046-321a-460e-b968-5dd056c338d9"
      },
      "source": [
        "test_on('/content/drive/MyDrive/test_cases')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a558f25bb18e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/test_cases'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-47a62672bef7>\u001b[0m in \u001b[0;36mtest_on\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     img = preprocess_input(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \"\"\"\n\u001b[1;32m    295\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 296\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/MyDrive/test_cases'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpQVGmZTEAPt"
      },
      "source": [
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "detector = FaceDetector()\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img, bboxs = detector.findFaces(img)\n",
        "\n",
        "    if bboxs:\n",
        "        x, y, w, h = bboxs[0][\"bbox\"]\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "        roi = roi / 255.\n",
        "        roi = np.expand_dims(roi, axis=0)\n",
        "        prediction = 'No glasses' if model.predict(roi) > 0.5 else 'glasses'\n",
        "        \n",
        "\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}